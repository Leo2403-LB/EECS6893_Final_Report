{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy joblib pyarrow scikit-learn networkx shapely"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyCGtxjMaIze",
        "outputId": "73ebe0f1-35ec-4bc4-e848-6a7ea40b409e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (2.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk31FSsPa5ic",
        "outputId": "c0c36237-282c-49ca-df9c-ad84a813682d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forest (lightweight version)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "import joblib\n",
        "\n",
        "DATA_PATH = \"here_speed_timeseries.parquet\"\n",
        "W = 5\n",
        "H = 3\n",
        "MODEL_OUT = \"rf_speed_model_light.joblib\"\n",
        "STATE_OUT = \"rf_last_window.parquet\"\n",
        "\n",
        "def build_supervised(df: pd.DataFrame, W: int, H: int):\n",
        "    X_list, Y_list = [], []\n",
        "\n",
        "    df = df.sort_values([\"item_id\", \"timestamp\"]).reset_index(drop=True)\n",
        "\n",
        "    for item_id, g in df.groupby(\"item_id\", sort=False):\n",
        "        y = g[\"target\"].to_numpy(dtype=np.float32)\n",
        "        if len(y) < W + H:\n",
        "            continue\n",
        "\n",
        "        for t in range(W - 1, len(y) - H):\n",
        "            x = y[t - (W - 1): t + 1]\n",
        "            y_future = y[t + 1: t + 1 + H]\n",
        "\n",
        "            if np.any(~np.isfinite(x)) or np.any(~np.isfinite(y_future)):\n",
        "                continue\n",
        "\n",
        "            X_list.append(x)\n",
        "            Y_list.append(y_future)\n",
        "\n",
        "    X = np.vstack(X_list)\n",
        "    Y = np.vstack(Y_list)\n",
        "    return X, Y\n",
        "\n",
        "def build_last_window_state(df: pd.DataFrame, W: int):\n",
        "    df = df.sort_values([\"item_id\", \"timestamp\"]).reset_index(drop=True)\n",
        "    rows = []\n",
        "\n",
        "    for item_id, g in df.groupby(\"item_id\", sort=False):\n",
        "        y = g[\"target\"].to_numpy(dtype=np.float32)\n",
        "        if len(y) < W:\n",
        "            continue\n",
        "        last = y[-W:]\n",
        "        row = {\"item_id\": str(item_id)}\n",
        "        for i in range(W):\n",
        "            row[f\"lag_{i+1}\"] = float(last[i])\n",
        "        rows.append(row)\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def main():\n",
        "    df = pd.read_parquet(DATA_PATH)\n",
        "    df[\"item_id\"] = df[\"item_id\"].astype(str)\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "    df[\"target\"] = pd.to_numeric(df[\"target\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"item_id\", \"timestamp\", \"target\"])\n",
        "    df = df[df[\"target\"] > 0]\n",
        "\n",
        "    print(\"Loaded df:\", df.shape, \"unique items:\", df[\"item_id\"].nunique())\n",
        "\n",
        "    X, Y = build_supervised(df, W=W, H=H)\n",
        "    print(\"Supervised X:\", X.shape, \"Y:\", Y.shape)\n",
        "\n",
        "    base = RandomForestRegressor(\n",
        "        n_estimators=80,\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=50,\n",
        "        max_features=\"sqrt\",\n",
        "        random_state=42,\n",
        "        n_jobs=1\n",
        "    )\n",
        "\n",
        "    model = MultiOutputRegressor(base, n_jobs=1)\n",
        "\n",
        "    print(\"Training lightweight RF...\")\n",
        "    model.fit(X, Y)\n",
        "    print(\"Training done.\")\n",
        "\n",
        "    joblib.dump({\"model\": model, \"W\": W, \"H\": H}, MODEL_OUT)\n",
        "    print(\"Saved model to:\", MODEL_OUT)\n",
        "\n",
        "    state = build_last_window_state(df, W=W)\n",
        "    state.to_parquet(STATE_OUT, index=False)\n",
        "    print(\"Saved last-window state:\", len(state))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0j5ecJubDqp",
        "outputId": "ab6b02c0-58d9-4644-c9c1-2fc812c659ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded df: (112403, 3) unique items: 3762\n",
            "Supervised X: (86122, 5) Y: (86122, 3)\n",
            "Training lightweight RF...\n",
            "Training done.\n",
            "Saved model to: rf_speed_model_light.joblib\n",
            "Saved last-window state: 3755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDoK5sBuaCvg",
        "outputId": "3952c5f4-1463-49f3-c27c-bde808b5462d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== BEFORE ===\n",
            "(42421728, 42435337, 0) speed(mph)= 25.0 travel_time(s)= 7.636161094365019\n",
            "(42421728, 42421731, 0) speed(mph)= 25.0 travel_time(s)= 12.350566807024558\n",
            "(42421728, 42432736, 0) speed(mph)= 25.0 travel_time(s)= 7.718150179116524\n",
            "(42421731, 42437916, 0) speed(mph)= 25.0 travel_time(s)= 7.708410966615876\n",
            "(42421731, 42432737, 0) speed(mph)= 25.0 travel_time(s)= 7.692265833780549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-699834859.py:135: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  now = datetime.utcnow()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RF] 0/3742 segments processed\n",
            "[RF] 200/3742 segments processed\n",
            "[RF] 400/3742 segments processed\n",
            "[RF] 600/3742 segments processed\n",
            "[RF] 800/3742 segments processed\n",
            "[RF] 1000/3742 segments processed\n",
            "[RF] 1200/3742 segments processed\n",
            "[RF] 1400/3742 segments processed\n",
            "[RF] 1600/3742 segments processed\n",
            "[RF] 1800/3742 segments processed\n",
            "[RF] 2000/3742 segments processed\n",
            "[RF] 2200/3742 segments processed\n",
            "[RF] 2400/3742 segments processed\n",
            "[RF] 2600/3742 segments processed\n",
            "[RF] 2800/3742 segments processed\n",
            "[RF] 3000/3742 segments processed\n",
            "[RF] 3200/3742 segments processed\n",
            "[RF] 3400/3742 segments processed\n",
            "[RF] 3600/3742 segments processed\n",
            "\n",
            "=== AFTER (t=7.80 min) ===\n",
            "(42421728, 42435337, 0) speed(mph)= 25.0 travel_time(s)= 7.636161094365019\n",
            "(42421728, 42421731, 0) speed(mph)= 25.0 travel_time(s)= 12.350566807024558\n",
            "(42421728, 42432736, 0) speed(mph)= 25.0 travel_time(s)= 7.718150179116524\n",
            "(42421731, 42437916, 0) speed(mph)= 25.0 travel_time(s)= 7.708410966615876\n",
            "(42421731, 42432737, 0) speed(mph)= 25.0 travel_time(s)= 7.692265833780549\n",
            "\n",
            "Total edges checked: 9935\n",
            "Edges with changed speed: 1403\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from datetime import datetime\n",
        "import networkx as nx\n",
        "\n",
        "# ------------------ paste function start ------------------\n",
        "def traffic_light_delay(u, v, data):\n",
        "    return 0\n",
        "\n",
        "DEFAULT_SPEED_MPH = 25.0\n",
        "\n",
        "def ml_predict_future_graph(\n",
        "    G_in: nx.MultiDiGraph,\n",
        "    current_time: datetime,\n",
        "    minutes_ahead: int = 30\n",
        ") -> nx.MultiDiGraph:\n",
        "    if not hasattr(ml_predict_future_graph, \"_loaded\"):\n",
        "        import pandas as pd\n",
        "        import joblib\n",
        "\n",
        "        bundle = joblib.load(\"rf_speed_model_light.joblib\")\n",
        "\n",
        "        ml_predict_future_graph._rf_model = bundle[\"model\"]\n",
        "        ml_predict_future_graph._W = int(bundle[\"W\"])\n",
        "        ml_predict_future_graph._H = int(bundle[\"H\"])\n",
        "\n",
        "        state = pd.read_parquet(\"rf_last_window.parquet\")\n",
        "        state[\"item_id\"] = state[\"item_id\"].astype(str)\n",
        "        ml_predict_future_graph._rf_state = state.set_index(\"item_id\")\n",
        "\n",
        "        map_df = pd.read_parquet(\"here_segment_to_osm_edge_filtered.parquet\")\n",
        "        map_df[\"segment_id\"] = map_df[\"segment_id\"].astype(str)\n",
        "        ml_predict_future_graph._segment_to_edge = (\n",
        "            map_df.set_index(\"segment_id\")[[\"u\", \"v\", \"key\"]].to_dict(\"index\")\n",
        "        )\n",
        "\n",
        "        ml_predict_future_graph._loaded = True\n",
        "\n",
        "    rf_model = ml_predict_future_graph._rf_model\n",
        "    W = ml_predict_future_graph._W\n",
        "    H = ml_predict_future_graph._H\n",
        "    rf_state = ml_predict_future_graph._rf_state\n",
        "    segment_to_edge = ml_predict_future_graph._segment_to_edge\n",
        "\n",
        "    G_pred = G_in.copy()\n",
        "\n",
        "    n_steps = int(round(float(minutes_ahead)))\n",
        "    if n_steps < 1:\n",
        "        n_steps = 1\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    total = len(segment_to_edge)\n",
        "\n",
        "    for i, (seg_id, info) in enumerate(segment_to_edge.items()):\n",
        "        if i % 200 == 0:\n",
        "            print(f\"[RF] {i}/{total} segments processed\")\n",
        "        u, v, k = info[\"u\"], info[\"v\"], info[\"key\"]\n",
        "        if not G_pred.has_edge(u, v, k):\n",
        "            continue\n",
        "\n",
        "        data = G_pred[u][v][k]\n",
        "        cur_speed_mph = data.get(\"speed\", DEFAULT_SPEED_MPH)\n",
        "        cur_speed_kmh = float(cur_speed_mph) * 1.609344\n",
        "        if not np.isfinite(cur_speed_kmh) or cur_speed_kmh <= 0:\n",
        "            cur_speed_kmh = 40.0\n",
        "\n",
        "        if seg_id in rf_state.index:\n",
        "            try:\n",
        "                window = rf_state.loc[seg_id, [f\"lag_{i+1}\" for i in range(W)]].to_numpy(dtype=np.float32)\n",
        "                if window.shape[0] != W or np.any(~np.isfinite(window)):\n",
        "                    raise ValueError(\"bad window\")\n",
        "                window[-1] = cur_speed_kmh\n",
        "            except Exception:\n",
        "                window = np.full((W,), cur_speed_kmh, dtype=np.float32)\n",
        "        else:\n",
        "            window = np.full((W,), cur_speed_kmh, dtype=np.float32)\n",
        "\n",
        "        remaining = n_steps\n",
        "        last_pred_kmh = cur_speed_kmh\n",
        "\n",
        "        while remaining > 0:\n",
        "            y = rf_model.predict(window.reshape(1, -1))[0]  # (H,)\n",
        "            y = np.asarray(y, dtype=np.float32)\n",
        "            if y.ndim != 1 or y.shape[0] < 1:\n",
        "                break\n",
        "\n",
        "            take = min(H, remaining)\n",
        "            for j in range(take):\n",
        "                pred_kmh = float(y[j])\n",
        "                if not np.isfinite(pred_kmh) or pred_kmh <= 0:\n",
        "                    pred_kmh = last_pred_kmh\n",
        "                last_pred_kmh = pred_kmh\n",
        "                window = np.concatenate([window[1:], np.array([pred_kmh], dtype=np.float32)])\n",
        "\n",
        "            remaining -= take\n",
        "\n",
        "        pred_mph = max(last_pred_kmh * 0.621371, 1.0)\n",
        "        data[\"speed\"] = float(pred_mph)\n",
        "\n",
        "        length_m = data.get(\"length\", 1.0)\n",
        "        speed_m_s = max(pred_mph * 0.44704, 1.0)\n",
        "        base_time = float(length_m / speed_m_s)\n",
        "        tl_penalty = traffic_light_delay(u, v, data)\n",
        "        data[\"travel_time\"] = base_time + tl_penalty\n",
        "\n",
        "    return G_pred\n",
        "# ------------------ paste function end ------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "    with open(\"manhattan_graph.gpickle\", \"rb\") as f:\n",
        "        G = pickle.load(f)\n",
        "\n",
        "    DEFAULT_SPEED = 25.0\n",
        "    for u, v, k, data in G.edges(keys=True, data=True):\n",
        "        if \"speed\" not in data:\n",
        "            data[\"speed\"] = DEFAULT_SPEED\n",
        "        if \"travel_time\" not in data:\n",
        "            length_m = data.get(\"length\", 1.0)\n",
        "            speed_m_s = max(data[\"speed\"] * 0.44704, 1.0)\n",
        "            data[\"travel_time\"] = float(length_m / speed_m_s)\n",
        "\n",
        "    sample_edges = list(G.edges(keys=True, data=True))[:5]\n",
        "    print(\"\\n=== BEFORE ===\")\n",
        "    for (u, v, k, d) in sample_edges:\n",
        "        print((u, v, k), \"speed(mph)=\", d.get(\"speed\"), \"travel_time(s)=\", d.get(\"travel_time\"))\n",
        "\n",
        "    now = datetime.utcnow()\n",
        "    t = 7.8\n",
        "    G2 = ml_predict_future_graph(G, now, minutes_ahead=t)\n",
        "\n",
        "    sample_edges2 = list(G2.edges(keys=True, data=True))[:5]\n",
        "    print(\"\\n=== AFTER (t=%.2f min) ===\" % t)\n",
        "    for (u, v, k, d) in sample_edges2:\n",
        "        print((u, v, k), \"speed(mph)=\", d.get(\"speed\"), \"travel_time(s)=\", d.get(\"travel_time\"))\n",
        "\n",
        "    changed = 0\n",
        "    total = 0\n",
        "    for (u, v, k, d1) in G.edges(keys=True, data=True):\n",
        "        d2 = G2.get_edge_data(u, v, k)\n",
        "        if d2 is None:\n",
        "            continue\n",
        "        total += 1\n",
        "        sp1 = d1.get(\"speed\")\n",
        "        sp2 = d2.get(\"speed\")\n",
        "        if sp1 != sp2:\n",
        "            changed += 1\n",
        "\n",
        "    print(\"\\nTotal edges checked:\", total)\n",
        "    print(\"Edges with changed speed:\", changed)\n",
        "    print(\"Done.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}